{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3316532,"sourceType":"datasetVersion","datasetId":10100}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-01T23:28:09.527660Z","iopub.execute_input":"2024-11-01T23:28:09.528117Z","iopub.status.idle":"2024-11-01T23:28:10.040124Z","shell.execute_reply.started":"2024-11-01T23:28:09.528064Z","shell.execute_reply":"2024-11-01T23:28:10.038620Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/yelp-dataset/Dataset_User_Agreement.pdf\n/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\n/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\n","output_type":"stream"}]},{"cell_type":"code","source":"import json \nimport pandas as pd\n\n# Open JSON file\ndata_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_business.json\")\n\n# Initializes the list to store JSON objects for each row\ndata = []\nfor line in data_file:\n    data.append(json.loads(line))  # Load the JSON object for each row and add it to the list\n\n# Convert the list to a DataFrame\nbusiness_df = pd.DataFrame(data)\n\n# closed file\ndata_file.close()\n\n# View the first 5 rows of data\nprint(business_df.head())\n# View basic data information\nbusiness_df.info()\n\nbusiness_df=pd.json_normalize(business_df.to_dict(orient='records'))\nprint(business_df.head())\n\nbusiness_df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:28:10.042723Z","iopub.execute_input":"2024-11-01T23:28:10.043406Z","iopub.status.idle":"2024-11-01T23:28:24.661022Z","shell.execute_reply.started":"2024-11-01T23:28:10.043343Z","shell.execute_reply":"2024-11-01T23:28:24.659830Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"              business_id                      name  \\\n0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n\n                           address           city state postal_code  \\\n0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n2             5255 E Broadway Blvd         Tucson    AZ       85711   \n3                      935 Race St   Philadelphia    PA       19107   \n4                    101 Walnut St     Green Lane    PA       18054   \n\n    latitude   longitude  stars  review_count  is_open  \\\n0  34.426679 -119.711197    5.0             7        0   \n1  38.551126  -90.335695    3.0            15        1   \n2  32.223236 -110.880452    3.5            22        0   \n3  39.955505  -75.155564    4.0            80        1   \n4  40.338183  -75.471659    4.5            13        1   \n\n                                          attributes  \\\n0                      {'ByAppointmentOnly': 'True'}   \n1             {'BusinessAcceptsCreditCards': 'True'}   \n2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n\n                                          categories  \\\n0  Doctors, Traditional Chinese Medicine, Naturop...   \n1  Shipping Centers, Local Services, Notaries, Ma...   \n2  Department Stores, Shopping, Fashion, Home & G...   \n3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n4                          Brewpubs, Breweries, Food   \n\n                                               hours  \n0                                               None  \n1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150346 entries, 0 to 150345\nData columns (total 14 columns):\n #   Column        Non-Null Count   Dtype  \n---  ------        --------------   -----  \n 0   business_id   150346 non-null  object \n 1   name          150346 non-null  object \n 2   address       150346 non-null  object \n 3   city          150346 non-null  object \n 4   state         150346 non-null  object \n 5   postal_code   150346 non-null  object \n 6   latitude      150346 non-null  float64\n 7   longitude     150346 non-null  float64\n 8   stars         150346 non-null  float64\n 9   review_count  150346 non-null  int64  \n 10  is_open       150346 non-null  int64  \n 11  attributes    136602 non-null  object \n 12  categories    150243 non-null  object \n 13  hours         127123 non-null  object \ndtypes: float64(3), int64(2), object(9)\nmemory usage: 16.1+ MB\n              business_id                      name  \\\n0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n\n                           address           city state postal_code  \\\n0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n2             5255 E Broadway Blvd         Tucson    AZ       85711   \n3                      935 Race St   Philadelphia    PA       19107   \n4                    101 Walnut St     Green Lane    PA       18054   \n\n    latitude   longitude  stars  review_count  ...  \\\n0  34.426679 -119.711197    5.0             7  ...   \n1  38.551126  -90.335695    3.0            15  ...   \n2  32.223236 -110.880452    3.5            22  ...   \n3  39.955505  -75.155564    4.0            80  ...   \n4  40.338183  -75.471659    4.5            13  ...   \n\n   attributes.AcceptsInsurance attributes.BestNights  attributes.BYOB  \\\n0                          NaN                   NaN              NaN   \n1                          NaN                   NaN              NaN   \n2                          NaN                   NaN              NaN   \n3                          NaN                   NaN              NaN   \n4                          NaN                   NaN              NaN   \n\n  attributes.Corkage attributes.BYOBCorkage attributes.HairSpecializesIn  \\\n0                NaN                    NaN                          NaN   \n1                NaN                    NaN                          NaN   \n2                NaN                    NaN                          NaN   \n3                NaN                    NaN                          NaN   \n4                NaN                    NaN                          NaN   \n\n  attributes.Open24Hours attributes.RestaurantsCounterService  \\\n0                    NaN                                  NaN   \n1                    NaN                                  NaN   \n2                    NaN                                  NaN   \n3                    NaN                                  NaN   \n4                    NaN                                  NaN   \n\n  attributes.AgesAllowed attributes.DietaryRestrictions  \n0                    NaN                            NaN  \n1                    NaN                            NaN  \n2                    NaN                            NaN  \n3                    NaN                            NaN  \n4                    NaN                            NaN  \n\n[5 rows x 60 columns]\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"            latitude      longitude          stars   review_count  \\\ncount  150346.000000  150346.000000  150346.000000  150346.000000   \nmean       36.671150     -89.357339       3.596724      44.866561   \nstd         5.872759      14.918502       0.974421     121.120136   \nmin        27.555127    -120.095137       1.000000       5.000000   \n25%        32.187293     -90.357810       3.000000       8.000000   \n50%        38.777413     -86.121179       3.500000      15.000000   \n75%        39.954036     -75.421542       4.500000      37.000000   \nmax        53.679197     -73.200457       5.000000    7568.000000   \n\n            is_open  hours  attributes  \ncount  150346.00000    0.0         0.0  \nmean        0.79615    NaN         NaN  \nstd         0.40286    NaN         NaN  \nmin         0.00000    NaN         NaN  \n25%         1.00000    NaN         NaN  \n50%         1.00000    NaN         NaN  \n75%         1.00000    NaN         NaN  \nmax         1.00000    NaN         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>stars</th>\n      <th>review_count</th>\n      <th>is_open</th>\n      <th>hours</th>\n      <th>attributes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150346.000000</td>\n      <td>150346.000000</td>\n      <td>150346.000000</td>\n      <td>150346.000000</td>\n      <td>150346.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>36.671150</td>\n      <td>-89.357339</td>\n      <td>3.596724</td>\n      <td>44.866561</td>\n      <td>0.79615</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.872759</td>\n      <td>14.918502</td>\n      <td>0.974421</td>\n      <td>121.120136</td>\n      <td>0.40286</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>27.555127</td>\n      <td>-120.095137</td>\n      <td>1.000000</td>\n      <td>5.000000</td>\n      <td>0.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>32.187293</td>\n      <td>-90.357810</td>\n      <td>3.000000</td>\n      <td>8.000000</td>\n      <td>1.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>38.777413</td>\n      <td>-86.121179</td>\n      <td>3.500000</td>\n      <td>15.000000</td>\n      <td>1.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>39.954036</td>\n      <td>-75.421542</td>\n      <td>4.500000</td>\n      <td>37.000000</td>\n      <td>1.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>53.679197</td>\n      <td>-73.200457</td>\n      <td>5.000000</td>\n      <td>7568.000000</td>\n      <td>1.00000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import json \nimport pandas as pd\n\n# Open JSON file\ndata_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_checkin.json\")\n\n# Initializes the list to store JSON objects for each row\ndata = []\nfor line in data_file:\n    data.append(json.loads(line))  # Load the JSON object for each row and add it to the list\n\n# Convert the list to a DataFrame\ncheckin_df = pd.DataFrame(data)\n\n# closed file\ndata_file.close()\n\n# View the first 5 rows of data\nprint(checkin_df.head())\n# View basic data information\ncheckin_df.info()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:28:24.663353Z","iopub.execute_input":"2024-11-01T23:28:24.664399Z","iopub.status.idle":"2024-11-01T23:28:29.428223Z","shell.execute_reply.started":"2024-11-01T23:28:24.664339Z","shell.execute_reply":"2024-11-01T23:28:29.426977Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"              business_id                                               date\n0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...\n1  --0iUa4sNDFiZFrAdIWhZQ  2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...\n2  --30_8IhuyMHbSOcNWd6DQ           2013-06-14 23:29:17, 2014-08-13 23:20:22\n3  --7PUidqRWpRSpXebiyxTg  2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...\n4  --7jw19RH9JKXgFohspgQw  2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 131930 entries, 0 to 131929\nData columns (total 2 columns):\n #   Column       Non-Null Count   Dtype \n---  ------       --------------   ----- \n 0   business_id  131930 non-null  object\n 1   date         131930 non-null  object\ndtypes: object(2)\nmemory usage: 2.0+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import json \nimport pandas as pd\n\n# Open JSON file\ndata_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_review.json\")\n\n# Initializes the list to store JSON objects for each row\ndata = []\nfor line in data_file:\n    data.append(json.loads(line))  # Load the JSON object for each row and add it to the list\n\n# Convert the list to a DataFrame\nreview_df = pd.DataFrame(data)\n\n# closed file\ndata_file.close()\n\n# View the first 5 rows of data\nprint(review_df.head())\n# View basic data information\nreview_df.info()\n\ncheckin_df.describe()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:28:29.431623Z","iopub.execute_input":"2024-11-01T23:28:29.432036Z","iopub.status.idle":"2024-11-01T23:30:48.895979Z","shell.execute_reply.started":"2024-11-01T23:28:29.431993Z","shell.execute_reply":"2024-11-01T23:30:48.894860Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"                review_id                 user_id             business_id  \\\n0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n\n   stars  useful  funny  cool  \\\n0    3.0       0      0     0   \n1    5.0       1      0     1   \n2    3.0       0      0     0   \n3    5.0       1      0     1   \n4    4.0       1      0     1   \n\n                                                text                 date  \n0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6990280 entries, 0 to 6990279\nData columns (total 9 columns):\n #   Column       Dtype  \n---  ------       -----  \n 0   review_id    object \n 1   user_id      object \n 2   business_id  object \n 3   stars        float64\n 4   useful       int64  \n 5   funny        int64  \n 6   cool         int64  \n 7   text         object \n 8   date         object \ndtypes: float64(1), int64(3), object(5)\nmemory usage: 480.0+ MB\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                   business_id  \\\ncount                   131930   \nunique                  131930   \ntop     ---kPU91CF4Lq2-WlRu9Lw   \nfreq                         1   \n\n                                                     date  \ncount                                              131930  \nunique                                             131930  \ntop     2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...  \nfreq                                                    1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>business_id</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>131930</td>\n      <td>131930</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>131930</td>\n      <td>131930</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n      <td>2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import json \nimport pandas as pd\n\n# Open JSON file\ndata_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_tip.json\")\n\n# Initializes the list to store JSON objects for each row\ndata = []\nfor line in data_file:\n    data.append(json.loads(line))  # Load the JSON object for each row and add it to the list\n\n# Convert the list to a DataFrame\ntip_df = pd.DataFrame(data)\n\n# closed file\ndata_file.close()\n\n# View the first 5 rows of data\nprint(tip_df.head())\n# View basic data information\ntip_df.info()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:30:48.897576Z","iopub.execute_input":"2024-11-01T23:30:48.898054Z","iopub.status.idle":"2024-11-01T23:31:00.047176Z","shell.execute_reply.started":"2024-11-01T23:30:48.898001Z","shell.execute_reply":"2024-11-01T23:31:00.045963Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"                  user_id             business_id  \\\n0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n\n                                                text                 date  \\\n0                     Avengers time with the ladies.  2012-05-18 02:17:21   \n1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10   \n2             It's open even when you think it isn't  2013-08-18 00:56:08   \n3                          Very decent fried chicken  2017-06-27 23:05:38   \n4             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n\n   compliment_count  \n0                 0  \n1                 0  \n2                 0  \n3                 0  \n4                 0  \n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 908915 entries, 0 to 908914\nData columns (total 5 columns):\n #   Column            Non-Null Count   Dtype \n---  ------            --------------   ----- \n 0   user_id           908915 non-null  object\n 1   business_id       908915 non-null  object\n 2   text              908915 non-null  object\n 3   date              908915 non-null  object\n 4   compliment_count  908915 non-null  int64 \ndtypes: int64(1), object(4)\nmemory usage: 34.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import json \nimport pandas as pd\n\n# Open JSON file\ndata_file = open(\"/kaggle/input/yelp-dataset/yelp_academic_dataset_user.json\")\n\n# Initializes the list to store JSON objects for each row\ndata = []\nfor line in data_file:\n    data.append(json.loads(line))  # Load the JSON object for each row and add it to the list\n\n# Convert the list to a DataFrame\nuser_df = pd.DataFrame(data)\n\n# closed file\ndata_file.close()\n\n# View the first 5 rows of data\nprint(user_df.head())\n# View basic data information\nuser_df.info()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:31:00.048614Z","iopub.execute_input":"2024-11-01T23:31:00.048979Z","iopub.status.idle":"2024-11-01T23:32:37.451401Z","shell.execute_reply.started":"2024-11-01T23:31:00.048939Z","shell.execute_reply":"2024-11-01T23:32:37.449166Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"                  user_id    name  review_count        yelping_since  useful  \\\n0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n3  SZDeASXq7o05mMNLshsdIA    Gwen           224  2005-11-29 04:38:33     512   \n4  hA5lMy-EnncsH4JoR-hFGQ   Karen            79  2007-01-05 19:40:59      29   \n\n   funny   cool                                              elite  \\\n0   1259   5994                                               2007   \n1  13066  27281  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n2   1010   1003                           2009,2010,2011,2012,2013   \n3    330    299                                     2009,2010,2011   \n4     15      7                                                      \n\n                                             friends  fans  ...  \\\n0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267  ...   \n1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138  ...   \n2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52  ...   \n3  enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...    28  ...   \n4  PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...     1  ...   \n\n   compliment_more  compliment_profile  compliment_cute  compliment_list  \\\n0               65                  55               56               18   \n1              264                 184              157              251   \n2               13                  10               17                3   \n3                4                   1                6                2   \n4                1                   0                0                0   \n\n   compliment_note  compliment_plain  compliment_cool  compliment_funny  \\\n0              232               844              467               467   \n1             1847              7054             3131              3131   \n2               66                96              119               119   \n3               12                16               26                26   \n4                1                 1                0                 0   \n\n   compliment_writer  compliment_photos  \n0                239                180  \n1               1521               1946  \n2                 35                 18  \n3                 10                  9  \n4                  0                  0  \n\n[5 rows x 22 columns]\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1987897 entries, 0 to 1987896\nData columns (total 22 columns):\n #   Column              Dtype  \n---  ------              -----  \n 0   user_id             object \n 1   name                object \n 2   review_count        int64  \n 3   yelping_since       object \n 4   useful              int64  \n 5   funny               int64  \n 6   cool                int64  \n 7   elite               object \n 8   friends             object \n 9   fans                int64  \n 10  average_stars       float64\n 11  compliment_hot      int64  \n 12  compliment_more     int64  \n 13  compliment_profile  int64  \n 14  compliment_cute     int64  \n 15  compliment_list     int64  \n 16  compliment_note     int64  \n 17  compliment_plain    int64  \n 18  compliment_cool     int64  \n 19  compliment_funny    int64  \n 20  compliment_writer   int64  \n 21  compliment_photos   int64  \ndtypes: float64(1), int64(16), object(5)\nmemory usage: 333.7+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"from sqlalchemy import create_engine\n!pip install PyMySql\nimport pymysql\nimport sqlalchemy\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:32:37.454517Z","iopub.execute_input":"2024-11-01T23:32:37.455135Z","iopub.status.idle":"2024-11-01T23:32:54.801651Z","shell.execute_reply.started":"2024-11-01T23:32:37.455067Z","shell.execute_reply":"2024-11-01T23:32:54.800393Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting PyMySql\n  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\nDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyMySql\nSuccessfully installed PyMySql-1.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!curl ifconfig.me","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:32:54.804424Z","iopub.execute_input":"2024-11-01T23:32:54.805514Z","iopub.status.idle":"2024-11-01T23:32:56.557406Z","shell.execute_reply.started":"2024-11-01T23:32:54.805450Z","shell.execute_reply":"2024-11-01T23:32:56.555850Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"34.145.83.221","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyodbc sqlalchemy\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:32:56.559433Z","iopub.execute_input":"2024-11-01T23:32:56.559853Z","iopub.status.idle":"2024-11-01T23:33:11.444619Z","shell.execute_reply.started":"2024-11-01T23:32:56.559810Z","shell.execute_reply":"2024-11-01T23:33:11.443082Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Collecting pyodbc\n  Downloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\nRequirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\nDownloading pyodbc-5.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyodbc\nSuccessfully installed pyodbc-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!apt-get update\n!apt-get install -y unixodbc-dev\n!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n!curl https://packages.microsoft.com/config/ubuntu/20.04/prod.list > /etc/apt/sources.list.d/mssql-release.list\n!apt-get update\n!ACCEPT_EULA=Y apt-get install -y msodbcsql18\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:33:11.449416Z","iopub.execute_input":"2024-11-01T23:33:11.449992Z","iopub.status.idle":"2024-11-01T23:33:45.991109Z","shell.execute_reply.started":"2024-11-01T23:33:11.449946Z","shell.execute_reply":"2024-11-01T23:33:45.989799Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Get:1 https://packages.cloud.google.com/apt gcsfuse-focal InRelease [1227 B]\nHit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \nGet:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [128 kB]        \nGet:4 https://packages.cloud.google.com/apt cloud-sdk InRelease [1618 B]       \nGet:5 http://security.ubuntu.com/ubuntu focal-security InRelease [128 kB]      \nGet:6 https://packages.cloud.google.com/apt gcsfuse-focal/main amd64 Packages [28.6 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [128 kB]      \nGet:8 https://packages.cloud.google.com/apt cloud-sdk/main amd64 Packages [3375 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [4546 kB]\nGet:10 https://packages.cloud.google.com/apt cloud-sdk/main all Packages [1564 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [4258 kB]\nGet:12 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [4081 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1566 kB]\nGet:14 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [33.5 kB]\nGet:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [4105 kB]\nGet:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1275 kB]\nGet:17 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [30.9 kB]\nFetched 25.2 MB in 3s (9327 kB/s)                             \nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  autoconf automake autotools-dev file libltdl-dev libmagic-mgc libmagic1\n  libodbc1 libsigsegv2 libtool m4 odbcinst odbcinst1debian2\nSuggested packages:\n  autoconf-archive gnu-standards autoconf-doc gettext libtool-doc libmyodbc\n  odbc-postgresql tdsodbc unixodbc-bin gfortran | fortran95-compiler gcj-jdk\n  m4-doc\nThe following NEW packages will be installed:\n  autoconf automake autotools-dev file libltdl-dev libmagic-mgc libmagic1\n  libodbc1 libsigsegv2 libtool m4 odbcinst odbcinst1debian2 unixodbc-dev\n0 upgraded, 14 newly installed, 0 to remove and 58 not upgraded.\nNeed to get 2212 kB of archives.\nAfter this operation, 15.3 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libmagic-mgc amd64 1:5.38-4 [218 kB]\nGet:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libmagic1 amd64 1:5.38-4 [75.9 kB]\nGet:3 http://archive.ubuntu.com/ubuntu focal/main amd64 file amd64 1:5.38-4 [23.3 kB]\nGet:4 http://archive.ubuntu.com/ubuntu focal/main amd64 libsigsegv2 amd64 2.12-2 [13.9 kB]\nGet:5 http://archive.ubuntu.com/ubuntu focal/main amd64 m4 amd64 1.4.18-4 [199 kB]\nGet:6 http://archive.ubuntu.com/ubuntu focal/main amd64 autoconf all 2.69-11.1 [321 kB]\nGet:7 http://archive.ubuntu.com/ubuntu focal/main amd64 autotools-dev all 20180224.1 [39.6 kB]\nGet:8 http://archive.ubuntu.com/ubuntu focal/main amd64 automake all 1:1.16.1-4ubuntu6 [522 kB]\nGet:9 http://archive.ubuntu.com/ubuntu focal/main amd64 libltdl-dev amd64 2.4.6-14 [162 kB]\nGet:10 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libodbc1 amd64 2.3.6-0.1ubuntu0.1 [190 kB]\nGet:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libtool all 2.4.6-14 [161 kB]\nGet:12 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 odbcinst1debian2 amd64 2.3.6-0.1ubuntu0.1 [41.7 kB]\nGet:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 odbcinst amd64 2.3.6-0.1ubuntu0.1 [14.5 kB]\nGet:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 unixodbc-dev amd64 2.3.6-0.1ubuntu0.1 [230 kB]\nFetched 2212 kB in 1s (3021 kB/s)     \nSelecting previously unselected package libmagic-mgc.\n(Reading database ... 115958 files and directories currently installed.)\nPreparing to unpack .../00-libmagic-mgc_1%3a5.38-4_amd64.deb ...\nUnpacking libmagic-mgc (1:5.38-4) ...\nSelecting previously unselected package libmagic1:amd64.\nPreparing to unpack .../01-libmagic1_1%3a5.38-4_amd64.deb ...\nUnpacking libmagic1:amd64 (1:5.38-4) ...\nSelecting previously unselected package file.\nPreparing to unpack .../02-file_1%3a5.38-4_amd64.deb ...\nUnpacking file (1:5.38-4) ...\nSelecting previously unselected package libsigsegv2:amd64.\nPreparing to unpack .../03-libsigsegv2_2.12-2_amd64.deb ...\nUnpacking libsigsegv2:amd64 (2.12-2) ...\nSelecting previously unselected package m4.\nPreparing to unpack .../04-m4_1.4.18-4_amd64.deb ...\nUnpacking m4 (1.4.18-4) ...\nSelecting previously unselected package autoconf.\nPreparing to unpack .../05-autoconf_2.69-11.1_all.deb ...\nUnpacking autoconf (2.69-11.1) ...\nSelecting previously unselected package autotools-dev.\nPreparing to unpack .../06-autotools-dev_20180224.1_all.deb ...\nUnpacking autotools-dev (20180224.1) ...\nSelecting previously unselected package automake.\nPreparing to unpack .../07-automake_1%3a1.16.1-4ubuntu6_all.deb ...\nUnpacking automake (1:1.16.1-4ubuntu6) ...\nSelecting previously unselected package libltdl-dev:amd64.\nPreparing to unpack .../08-libltdl-dev_2.4.6-14_amd64.deb ...\nUnpacking libltdl-dev:amd64 (2.4.6-14) ...\nSelecting previously unselected package libodbc1:amd64.\nPreparing to unpack .../09-libodbc1_2.3.6-0.1ubuntu0.1_amd64.deb ...\nUnpacking libodbc1:amd64 (2.3.6-0.1ubuntu0.1) ...\nSelecting previously unselected package libtool.\nPreparing to unpack .../10-libtool_2.4.6-14_all.deb ...\nUnpacking libtool (2.4.6-14) ...\nSelecting previously unselected package odbcinst1debian2:amd64.\nPreparing to unpack .../11-odbcinst1debian2_2.3.6-0.1ubuntu0.1_amd64.deb ...\nUnpacking odbcinst1debian2:amd64 (2.3.6-0.1ubuntu0.1) ...\nSelecting previously unselected package odbcinst.\nPreparing to unpack .../12-odbcinst_2.3.6-0.1ubuntu0.1_amd64.deb ...\nUnpacking odbcinst (2.3.6-0.1ubuntu0.1) ...\nSelecting previously unselected package unixodbc-dev:amd64.\nPreparing to unpack .../13-unixodbc-dev_2.3.6-0.1ubuntu0.1_amd64.deb ...\nUnpacking unixodbc-dev:amd64 (2.3.6-0.1ubuntu0.1) ...\nSetting up libmagic-mgc (1:5.38-4) ...\nSetting up libmagic1:amd64 (1:5.38-4) ...\nSetting up file (1:5.38-4) ...\nSetting up autotools-dev (20180224.1) ...\nSetting up libsigsegv2:amd64 (2.12-2) ...\nSetting up libodbc1:amd64 (2.3.6-0.1ubuntu0.1) ...\nSetting up libtool (2.4.6-14) ...\nSetting up m4 (1.4.18-4) ...\nSetting up autoconf (2.69-11.1) ...\nSetting up automake (1:1.16.1-4ubuntu6) ...\nupdate-alternatives: using /usr/bin/automake-1.16 to provide /usr/bin/automake (automake) in auto mode\nupdate-alternatives: warning: skip creation of /usr/share/man/man1/automake.1.gz because associated file /usr/share/man/man1/automake-1.16.1.gz (of link group automake) doesn't exist\nupdate-alternatives: warning: skip creation of /usr/share/man/man1/aclocal.1.gz because associated file /usr/share/man/man1/aclocal-1.16.1.gz (of link group automake) doesn't exist\nSetting up libltdl-dev:amd64 (2.4.6-14) ...\nSetting up odbcinst1debian2:amd64 (2.3.6-0.1ubuntu0.1) ...\nSetting up unixodbc-dev:amd64 (2.3.6-0.1ubuntu0.1) ...\nSetting up odbcinst (2.3.6-0.1ubuntu0.1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.16) ...\nProcessing triggers for man-db (2.9.1-1) ...\nProcessing triggers for install-info (6.7.0.dfsg.2-5) ...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   983  100   983    0     0  10311      0 --:--:-- --:--:-- --:--:--     0-- --:--:-- 10347\nOK\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    89  100    89    0     0    919      0 --:--:-- --:--:-- --:--:--   917\nGet:1 https://packages.microsoft.com/ubuntu/20.04/prod focal InRelease [3632 B]\nHit:2 https://packages.cloud.google.com/apt gcsfuse-focal InRelease            \nHit:3 https://packages.cloud.google.com/apt cloud-sdk InRelease                \nGet:4 https://packages.microsoft.com/ubuntu/20.04/prod focal/main all Packages [2938 B]\nHit:5 http://security.ubuntu.com/ubuntu focal-security InRelease               \nHit:6 http://archive.ubuntu.com/ubuntu focal InRelease              \nGet:7 https://packages.microsoft.com/ubuntu/20.04/prod focal/main armhf Packages [22.8 kB]\nGet:8 https://packages.microsoft.com/ubuntu/20.04/prod focal/main arm64 Packages [68.1 kB]\nGet:9 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 Packages [319 kB]\nHit:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease               \nHit:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease\nFetched 417 kB in 1s (373 kB/s)\nReading package lists... Done\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following additional packages will be installed:\n  libodbc1 odbcinst odbcinst1debian2 unixodbc unixodbc-dev\nSuggested packages:\n  msodbcsql17 unixodbc-bin\nThe following NEW packages will be installed:\n  msodbcsql18 unixodbc\nThe following packages will be upgraded:\n  libodbc1 odbcinst odbcinst1debian2 unixodbc-dev\n4 upgraded, 2 newly installed, 0 to remove and 58 not upgraded.\nNeed to get 1456 kB of archives.\nAfter this operation, 142 kB disk space will be freed.\nGet:1 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 odbcinst amd64 2.3.11-1 [21.3 kB]\nGet:2 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 unixodbc-dev amd64 2.3.11-1 [42.4 kB]\nGet:3 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 odbcinst1debian2 amd64 2.3.11-1 [99.8 kB]\nGet:4 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 libodbc1 amd64 2.3.11-1 [486 kB]\nGet:5 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 unixodbc amd64 2.3.11-1 [51.5 kB]\nGet:6 https://packages.microsoft.com/ubuntu/20.04/prod focal/main amd64 msodbcsql18 amd64 18.4.1.1-1 [755 kB]\nFetched 1456 kB in 0s (7117 kB/s)    \nPreconfiguring packages ...\n(Reading database ... 116412 files and directories currently installed.)\nPreparing to unpack .../0-odbcinst_2.3.11-1_amd64.deb ...\nUnpacking odbcinst (2.3.11-1) over (2.3.6-0.1ubuntu0.1) ...\nPreparing to unpack .../1-unixodbc-dev_2.3.11-1_amd64.deb ...\nUnpacking unixodbc-dev (2.3.11-1) over (2.3.6-0.1ubuntu0.1) ...\nPreparing to unpack .../2-odbcinst1debian2_2.3.11-1_amd64.deb ...\nUnpacking odbcinst1debian2:amd64 (2.3.11-1) over (2.3.6-0.1ubuntu0.1) ...\nPreparing to unpack .../3-libodbc1_2.3.11-1_amd64.deb ...\nUnpacking libodbc1:amd64 (2.3.11-1) over (2.3.6-0.1ubuntu0.1) ...\nSelecting previously unselected package unixodbc.\nPreparing to unpack .../4-unixodbc_2.3.11-1_amd64.deb ...\nUnpacking unixodbc (2.3.11-1) ...\nSelecting previously unselected package msodbcsql18.\nPreparing to unpack .../5-msodbcsql18_18.4.1.1-1_amd64.deb ...\nUnpacking msodbcsql18 (18.4.1.1-1) ...\nSetting up libodbc1:amd64 (2.3.11-1) ...\nSetting up odbcinst (2.3.11-1) ...\nSetting up odbcinst1debian2:amd64 (2.3.11-1) ...\nSetting up unixodbc (2.3.11-1) ...\nSetting up msodbcsql18 (18.4.1.1-1) ...\nodbcinst: Driver installed. Usage count increased to 1. \n    Target directory is /etc\nSetting up unixodbc-dev (2.3.11-1) ...\nProcessing triggers for libc-bin (2.31-0ubuntu9.16) ...\nProcessing triggers for man-db (2.9.1-1) ...\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyodbc\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:33:45.992877Z","iopub.execute_input":"2024-11-01T23:33:45.993291Z","iopub.status.idle":"2024-11-01T23:34:00.484023Z","shell.execute_reply.started":"2024-11-01T23:33:45.993221Z","shell.execute_reply":"2024-11-01T23:34:00.482624Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyodbc in /opt/conda/lib/python3.10/site-packages (5.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install sqlalchemy pymssql pandas","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:34:00.485962Z","iopub.execute_input":"2024-11-01T23:34:00.486408Z","iopub.status.idle":"2024-11-01T23:34:15.721861Z","shell.execute_reply.started":"2024-11-01T23:34:00.486361Z","shell.execute_reply":"2024-11-01T23:34:15.720502Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.10/site-packages (2.0.30)\nCollecting pymssql\n  Downloading pymssql-2.3.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.1 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (4.12.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy) (3.0.3)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nDownloading pymssql-2.3.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymssql\nSuccessfully installed pymssql-2.3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sqlalchemy import create_engine\n\n# Azure SQL Database credentials\nusername = 'xiaoxue-zhang'\npassword = 'group12345!'\nhost = 'xiaoxueproject.database.windows.net'\ndatabase = 'badm554_project'\n\n# Modified connection string for pymssql with additional parameters\nconnection_string = f\"mssql+pymssql://{username}:{password}@{host}:1433/{database}?charset=utf8\"\n\n# Create an SQLAlchemy engine\nengine = create_engine(connection_string)\n\n# Test the connection without interacting with any table\ntry:\n    with engine.connect() as connection:\n        print(\"Connection to Azure SQL Database successful!\")\nexcept Exception as e:\n    print(f\"Connection failed: {e}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:48:53.296466Z","iopub.execute_input":"2024-11-01T23:48:53.296974Z","iopub.status.idle":"2024-11-01T23:48:54.813293Z","shell.execute_reply.started":"2024-11-01T23:48:53.296927Z","shell.execute_reply":"2024-11-01T23:48:54.812116Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Connection to Azure SQL Database successful!\n","output_type":"stream"}]},{"cell_type":"code","source":"review_df.to_sql(name = \"review_df\", con = engine, if_exists='replace', index=True, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-01T23:48:57.185301Z","iopub.execute_input":"2024-11-01T23:48:57.185778Z","iopub.status.idle":"2024-11-02T01:29:24.056701Z","shell.execute_reply.started":"2024-11-01T23:48:57.185731Z","shell.execute_reply":"2024-11-02T01:29:24.055305Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"6963"},"metadata":{}}]},{"cell_type":"code","source":"user_df.to_sql(name = \"user_df\", con = engine, if_exists='replace', index=True, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T01:29:24.059390Z","iopub.execute_input":"2024-11-02T01:29:24.060007Z","iopub.status.idle":"2024-11-02T02:43:24.327550Z","shell.execute_reply.started":"2024-11-02T01:29:24.059913Z","shell.execute_reply":"2024-11-02T02:43:24.326259Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1640"},"metadata":{}}]},{"cell_type":"code","source":"business_df.to_sql(name = \"business_df\", con = engine, if_exists='replace', index=True, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T02:43:24.329357Z","iopub.execute_input":"2024-11-02T02:43:24.329737Z","iopub.status.idle":"2024-11-02T02:54:18.584053Z","shell.execute_reply.started":"2024-11-02T02:43:24.329690Z","shell.execute_reply":"2024-11-02T02:54:18.582556Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}]},{"cell_type":"code","source":"checkin_df.to_sql(name = \"checkin_df\", con = engine, if_exists='replace', index=True, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T02:54:18.586698Z","iopub.execute_input":"2024-11-02T02:54:18.587081Z","iopub.status.idle":"2024-11-02T02:57:10.837686Z","shell.execute_reply.started":"2024-11-02T02:54:18.587041Z","shell.execute_reply":"2024-11-02T02:57:10.836541Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"1217"},"metadata":{}}]},{"cell_type":"code","source":"tip_df.to_sql(name = \"tip_df\", con = engine, if_exists='replace', index=True, chunksize=50000)","metadata":{"execution":{"iopub.status.busy":"2024-11-02T02:57:10.839314Z","iopub.execute_input":"2024-11-02T02:57:10.839671Z","iopub.status.idle":"2024-11-02T03:03:45.346315Z","shell.execute_reply.started":"2024-11-02T02:57:10.839633Z","shell.execute_reply":"2024-11-02T03:03:45.345299Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"1864"},"metadata":{}}]},{"cell_type":"code","source":"#SQL QUERIES CAN BE FOUND ON THE GOOGLE COLAB NOTEBOOK SUBMITTED","metadata":{},"execution_count":null,"outputs":[]}]}